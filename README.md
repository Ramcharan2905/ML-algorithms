# Machine Learning & Deep Learning Algorithms from Scratch

This repository contains implementations of core **machine learning** and **deep learning** algorithms built completely from scratch in **Python** and **NumPy**, with some neural network components using **TensorFlow** for comparison and experimentation.

---

## ğŸ“˜ Overview

The project demonstrates how foundational ML and DL algorithms work under the hood without relying on high-level libraries like `scikit-learn` or `keras`.  
Each algorithm is written clearly and organized into logical modules for learning, experimentation, and extension.

---

## ğŸ§  Structure

```
algorithms from scratch/
â”‚
â”œâ”€â”€ ML algorithms/           # Classical ML implementations (NumPy-based)
â”‚   â”œâ”€â”€ LinearRegression.ipynb
â”‚   â”œâ”€â”€ LogisticRegression.ipynb
â”‚   â”œâ”€â”€ DecisionTree.ipynb
â”‚   â”œâ”€â”€ KMeans.ipynb
â”‚   â””â”€â”€ PCA.ipynb
â”‚
â”œâ”€â”€ DL algorithms/           # Neural networks & deep learning models
â”‚   â”œâ”€â”€ backpropagation.ipynb
â”‚   â”œâ”€â”€ cnn_model.ipynb
â”‚   â”œâ”€â”€ rnn_model.ipynb
â”‚   â”œâ”€â”€ transformer.ipynb
â”‚   â”œâ”€â”€ autoencoders.ipynb
â”‚   â””â”€â”€ sequential_model_tf.ipynb
â”‚
â”œâ”€â”€ losses/                  # Loss functions (MSE, Cross-Entropy, etc.)
â”œâ”€â”€ metrics/                 # Evaluation metrics (Accuracy, Confusion Matrix, etc.)
â”œâ”€â”€ optimizers/              # Optimizers (SGD, Adam, RMSProp, etc.)
â”œâ”€â”€ preprocessing/           # Data preprocessing utilities
â””â”€â”€ utils/                   # Helper functions
```

---

## âš™ï¸ Tech Stack

- **Python 3.10+**
- **NumPy** â€” mathematical and array operations  
- **TensorFlow** â€” neural network models  
- **Jupyter Notebook** â€” interactive implementation and visualization  

---

## ğŸš€ Features

- From-scratch ML algorithms (no external ML libraries)  
- Full neural network pipeline built manually (forward, backward, gradient)  
- Deep learning models using TensorFlow for benchmarking  
- Well-structured and modular code  
- Educational clarity for ML fundamentals  

---

## ğŸ§© Example Topics

- Linear & Logistic Regression  
- Decision Trees  
- K-Means Clustering  
- Principal Component Analysis (PCA)  
- Feedforward Neural Networks  
- CNNs, RNNs, Transformers  
- Loss and Metric functions  
- Optimizers and Gradient Computation  

---

## â–¶ï¸ How to Run

1. **Clone the repository**
   ```bash
   git clone https://github.com/Ramcharan2905/algorithms-from-scratch.git
   cd algorithms-from-scratch
   ```

2. **Create a virtual environment and install dependencies**
   ```bash
   python -m venv venv
   source venv/bin/activate      # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Launch Jupyter Notebook**
   ```bash
   jupyter notebook
   ```
   Open any notebook under `ML algorithms/` or `DL algorithms/` to explore and run the implementations.

---

## ğŸ“ˆ Learning Purpose

This repository is designed for students and practitioners who want to:

- Understand the math and logic behind ML/DL models  
- Build end-to-end algorithms from basic principles  
- Visualize and test implementations step by step  

---

## ğŸ‘¤ Author

**Gudala Geeta Ramcharan**  
Machine Learning Enthusiast | Python Developer  
GitHub: [Ramcharan2905](https://github.com/Ramcharan2905)

---

## â­ Acknowledgments

Inspired by core ML theory, Andrew Ngâ€™s ML course, and TensorFlow educational resources.
